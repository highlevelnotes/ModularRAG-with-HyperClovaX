{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 250603 테스트\n",
        "\n",
        "* 정의된 함수 옮기기\n",
        "* 정의된 클래스 옮기기\n",
        "* hcx-005 모델 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6GUHybGwnsPh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import jsonlines\n",
        "from langchain.schema import Document\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_naver.embeddings import ClovaXEmbeddings\n",
        "from langchain_milvus.vectorstores import Milvus\n",
        "from uuid import uuid4\n",
        "from langchain_naver.chat_models import ChatClovaX\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "import pandas as pd\n",
        "import pytz\n",
        "\n",
        "from datasets import Dataset\n",
        "from datetime import timedelta\n",
        "from operator import itemgetter\n",
        "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import (\n",
        "  AttributeInfo,\n",
        "  StructuredQueryOutputParser,\n",
        "  get_query_constructor_prompt\n",
        ")\n",
        "from langchain_teddynote.evaluator import GroundednessChecker\n",
        "from langchain.retrievers.self_query.milvus import MilvusTranslator\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
        "import warnings\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LP2hMGEp0B2P"
      },
      "outputs": [],
      "source": [
        "embeddings = ClovaXEmbeddings(\n",
        "    model='bge-m3'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adjust_time_filter_to_week(time_filter):\n",
        "    \"\"\"\n",
        "    특정 날짜(YYYY-MM-DD)가 주어진 경우, 해당 날짜를 포함하는 주(월~일)의\n",
        "    첫 번째 날(월요일)과 마지막 날(일요일)로 변환하는 함수.\n",
        "\n",
        "    :param time_filter: dict, {\"start_date\": datetime, \"end_date\": datetime}\n",
        "    :return: dict, {\"start_date\": datetime, \"end_date\": datetime}\n",
        "    \"\"\"\n",
        "    # Extract start_date and end_date from time_filter\n",
        "    start_date = time_filter.start_date\n",
        "    end_date = time_filter.end_date\n",
        "\n",
        "    # Handle the case where start_date or end_date is None\n",
        "    if start_date is None or end_date is None:\n",
        "        if start_date is not None and end_date is None:\n",
        "            start_of_week = start_date - timedelta(days=start_date.weekday())  # 월요일 찾기\n",
        "            end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "            return {\n",
        "                \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "                \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "            }\n",
        "        elif end_date is not None and start_date is None:\n",
        "            start_of_week = end_date - timedelta(days=end_date.weekday())  # 월요일 찾기\n",
        "            end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "            return {\n",
        "                \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "                \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "            }\n",
        "        else:\n",
        "            return None  # or return the time_filter as is if you prefer\n",
        "\n",
        "    # 날짜가 동일한 경우, 주의 첫 번째 날(월요일)과 마지막 날(일요일)로 변경\n",
        "    if start_date.year == end_date.year and start_date.month==end_date.month and start_date.day==end_date.day:\n",
        "        start_of_week = start_date - timedelta(days=start_date.weekday())  # 월요일 찾기\n",
        "        end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "        return {\n",
        "            \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "            \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "        }\n",
        "\n",
        "    # 날짜가 다르면 기존 time_filter 유지\n",
        "    return {\n",
        "        \"start_date\": start_date,\n",
        "        \"end_date\": end_date\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel\n",
        "import instructor\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "class TimeFilter(BaseModel):\n",
        "    start_date: Optional[datetime] = None\n",
        "    end_date: Optional[datetime] = None\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    query: str\n",
        "    time_filter: TimeFilter\n",
        "\n",
        "class Label(BaseModel):\n",
        "    chunk_id: int = Field(description=\"The unique identifier of the text chunk\")\n",
        "    chain_of_thought: str = Field(\n",
        "        description=\"The reasoning process used to evaluate the relevance\"\n",
        "    )\n",
        "    relevancy: int = Field(\n",
        "        description=\"Relevancy score from 0 to 10, where 10 is most relevant\",\n",
        "        ge=0,\n",
        "        le=10,\n",
        "    )\n",
        "\n",
        "class RerankedResults(BaseModel):\n",
        "    labels: list[Label] = Field(description=\"List of labeled and ranked chunks\")\n",
        "\n",
        "    @field_validator(\"labels\")\n",
        "    @classmethod\n",
        "    def model_validate(cls, v: list[Label]) -> list[Label]:\n",
        "        return sorted(v, key=lambda x: x.relevancy, reverse=True)\n",
        "\n",
        "def rerank_results(query: str, chunks: list[dict]) -> RerankedResults:\n",
        "    # HCX-005 모델을 사용하는 ChatClovaX 인스턴스 생성\n",
        "    chat = ChatClovaX(\n",
        "        base_url=\"https://clovastudio.stream.ntruss.com/v1/openai\",\n",
        "        model=\"HCX-005\",\n",
        "    )\n",
        "\n",
        "    # 프롬프트 구성\n",
        "    system_prompt = \"\"\"\n",
        "You are an expert search result ranker. Your task is to evaluate the relevance of each text chunk to the given query and assign a relevancy score.\n",
        "\n",
        "For each chunk:\n",
        "1. Analyze its content in relation to the query.\n",
        "2. Provide a chain of thought explaining your reasoning.\n",
        "3. Assign a relevancy score from 0 to 10, where 10 is most relevant.\n",
        "\n",
        "Be objective and consistent in your evaluations.\n",
        "\"\"\"\n",
        "\n",
        "    # chunk 정보를 텍스트로 변환\n",
        "    chunk_text = \"\"\n",
        "    for chunk in chunks:\n",
        "        chunk_text += f'<chunk id=\"{chunk[\"id\"]}\">\\n{chunk[\"text\"]}\\n</chunk>\\n'\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "<query>{query}</query>\n",
        "\n",
        "<chunks_to_rank>\n",
        "{chunk_text}\n",
        "</chunks_to_rank>\n",
        "\n",
        "Please provide a JSON array of objects with keys: id, score, reasoning.\n",
        "\"\"\"\n",
        "\n",
        "    # HCX-005에 메시지 전달\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    response = chat.invoke(messages)\n",
        "    # response.content에 결과 JSON이 들어있다고 가정\n",
        "    import json\n",
        "    labels = json.loads(response.content)\n",
        "    return RerankedResults(labels=[Label(**label) for label in labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_query_date(question):\n",
        "    today = datetime(2025, 1, 25)\n",
        "    days_since_last_friday = (today.weekday() - 4) % 7\n",
        "    last_friday = today - timedelta(days=days_since_last_friday)\n",
        "    issue_date = last_friday.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # ChatClovaX 인스턴스 생성\n",
        "    chat = ChatClovaX(\n",
        "        base_url=\"https://clovastudio.stream.ntruss.com/v1/openai\",\n",
        "        model=\"HCX-005\",  # 가장 성능 좋은 모델\n",
        "    )\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "        You are an AI assistant that extracts date ranges from financial queries.\n",
        "        The current report date is {issue_date}.\n",
        "        Your task is to extract the relevant date or date range from the user's query\n",
        "        and format it in YYYY-MM-DD format.\n",
        "        If no date is specified, answer with None value.\n",
        "        Return your answer as a JSON object: {{\"time_filter\": \"YYYY-MM-DD to YYYY-MM-DD\"}} or {{\"time_filter\": null}}\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "\n",
        "    response = chat.invoke(messages)\n",
        "    import json\n",
        "    try:\n",
        "        data = json.loads(response.content)\n",
        "        time_filter = data.get(\"time_filter\", None)\n",
        "    except Exception:\n",
        "        time_filter = None\n",
        "\n",
        "    parsed_dates = adjust_time_filter_to_week(time_filter)\n",
        "\n",
        "    if parsed_dates:\n",
        "        start = parsed_dates['start_date']\n",
        "        end = parsed_dates['end_date']\n",
        "    else:\n",
        "        start = None\n",
        "        end = None\n",
        "\n",
        "    if start is None or end is None:\n",
        "        expr = None\n",
        "    else:\n",
        "        expr = f\"issue_date >= '{start.strftime('%Y%m%d')}' AND issue_date <= '{end.strftime('%Y%m%d')}'\"\n",
        "    return expr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_list(example):\n",
        "    if isinstance(example[\"contexts\"], list):\n",
        "        contexts = example[\"contexts\"]\n",
        "    else:\n",
        "        try:\n",
        "            contexts = json.loads(example[\"contexts\"])\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON Decode Error: {example['contexts']} - {e}\")\n",
        "            contexts = []\n",
        "    return {\"contexts\": contexts}\n",
        "\n",
        "def generate_expr(question: str) -> dict:\n",
        "    expr = get_query_date(question)\n",
        "    return {\"expr\": expr}\n",
        "\n",
        "def reranking(docs, question, k=15):\n",
        "    chunks = [{\"id\": idx, \"issue_date\": doc.metadata['issue_date'],  \"text\": doc.page_content} for idx, doc in enumerate(docs)]\n",
        "    documents_with_metadata = [{\"text\": doc.page_content, \"metadata\": doc.metadata} for doc in docs]\n",
        "    reranked_results = rerank_results(query=question, chunks=chunks)\n",
        "\n",
        "    chunk_dict = {chunk[\"id\"]: chunk[\"text\"] for chunk in chunks}\n",
        "    top_k_results = [chunk_dict.get(label.chunk_id, \"\") for label in reranked_results.labels[:k] if label.chunk_id in chunk_dict]\n",
        "\n",
        "    reranked_results_with_metadata = []\n",
        "    for reranked_result in top_k_results:\n",
        "        page_content = reranked_result\n",
        "\n",
        "        matching_metadata = None\n",
        "        for doc in documents_with_metadata:\n",
        "            if doc[\"text\"] == page_content:\n",
        "                matching_metadata = doc[\"metadata\"]\n",
        "                break\n",
        "\n",
        "        document = Document(\n",
        "            metadata=matching_metadata,\n",
        "            page_content=page_content\n",
        "        )\n",
        "        reranked_results_with_metadata.append(document)\n",
        "\n",
        "    context_rerankedNbm25 = reranked_results_with_metadata\n",
        "    return context_rerankedNbm25\n",
        "\n",
        "text_prompt = PromptTemplate.from_template(\n",
        "'''\n",
        "today is '2025-01-25'. You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "If question has date expressions, context already filtered with the date expression, so ignore about the date and answer without it.\n",
        "Answer in Korean. Answer in detail.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:'''\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-8-7730f8b3bed0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m question_answer_relevant = GroundednessChecker(\n\u001b[0;32m      2\u001b[0m   \u001b[0mllm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mChatClovaX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://clovastudio.stream.ntruss.com/v1/openai\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"HCX-005\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'question-answer'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m ).create()\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Jo\\AppData\\Local\\Programs\\Python311\\Lib\\site-packages\\langchain_teddynote\\evaluator.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[0mllm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_structured_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGroundnessAnswerRetrievalScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"question-answer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0mllm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_structured_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGroundnessQuestionScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"question-retrieval\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mllm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_structured_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGroundnessQuestionRetrievalScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Jo\\AppData\\Local\\Programs\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\u001b[0m in \u001b[0;36mwith_structured_output\u001b[1;34m(self, schema, include_raw, **kwargs)\u001b[0m\n\u001b[0;32m   1298\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1300\u001b[1;33m         llm = self.bind_tools(\n\u001b[0m\u001b[0;32m   1301\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"any\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Jo\\AppData\\Local\\Programs\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\u001b[0m in \u001b[0;36mbind_tools\u001b[1;34m(self, tools, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   1172\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m     ) -> Runnable[LanguageModelInput, BaseMessage]:\n\u001b[1;32m-> 1174\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m     def with_structured_output(\n",
            "\u001b[1;31mNotImplementedError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "question_answer_relevant = GroundednessChecker(\n",
        "  llm=ChatClovaX(model=\"HCX-005\"), target='question-answer'\n",
        ").create()\n",
        "\n",
        "@chain\n",
        "def kill_table(result):\n",
        "    if question_answer_relevant.invoke({'question': result['question'], 'answer': result['text']}).score == 'no':\n",
        "        result['context'] = table_chain.invoke({'question': result['question']})\n",
        "    else:\n",
        "        result['context'] = result['text']\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='안녕하세요, 사용자님! 저는 CLOVA X입니다.\\n\\n궁금하신 내용이나 도움이 필요하신 일이 있으시다면 말씀해 주세요. 제가 알고 있는 지식과 능력으로 최대한 도움을 드리겠습니다.\\n\\n좋은 하루 보내세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 7, 'total_tokens': 53, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'HCX-005', 'system_fingerprint': None, 'id': 'ef22c03d65a34a2e81170285a9b41139', 'finish_reason': 'stop', 'logprobs': None}, id='run-9eafd6a8-df90-4e96-9376-340253599f12-0', usage_metadata={'input_tokens': 7, 'output_tokens': 46, 'total_tokens': 53, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_naver import ChatClovaX\n",
        "\n",
        "chat = ChatClovaX(\n",
        "    model=\"HCX-005\"\n",
        ")\n",
        "chat.invoke(\"hi!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "URI = 'http://127.0.0.1:19530'\n",
        "\n",
        "text_db = Milvus(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args = {'uri': URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='text_db_2'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
