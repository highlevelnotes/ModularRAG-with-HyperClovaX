{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 250604 LCEL\n",
        "\n",
        "* HCX-005 기반 GroundednessChecker 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GUHybGwnsPh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import jsonlines\n",
        "from langchain.schema import Document\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_naver.embeddings import ClovaXEmbeddings\n",
        "from langchain_milvus.vectorstores import Milvus\n",
        "from uuid import uuid4\n",
        "from langchain_naver.chat_models import ChatClovaX\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "import pandas as pd\n",
        "import pytz\n",
        "\n",
        "from datasets import Dataset\n",
        "from datetime import timedelta\n",
        "from operator import itemgetter\n",
        "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import (\n",
        "  AttributeInfo,\n",
        "  StructuredQueryOutputParser,\n",
        "  get_query_constructor_prompt\n",
        ")\n",
        "from langchain_teddynote.evaluator import GroundednessChecker\n",
        "from langchain.retrievers.self_query.milvus import MilvusTranslator\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
        "import warnings\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP2hMGEp0B2P"
      },
      "outputs": [],
      "source": [
        "embeddings = ClovaXEmbeddings(\n",
        "    model='bge-m3'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel\n",
        "import instructor\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "class TimeFilter(BaseModel):\n",
        "    start_date: Optional[datetime] = None\n",
        "    end_date: Optional[datetime] = None\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    query: str\n",
        "    time_filter: TimeFilter\n",
        "\n",
        "class Label(BaseModel):\n",
        "    chunk_id: int = Field(description=\"The unique identifier of the text chunk\")\n",
        "    chain_of_thought: str = Field(\n",
        "        description=\"The reasoning process used to evaluate the relevance\"\n",
        "    )\n",
        "    relevancy: int = Field(\n",
        "        description=\"Relevancy score from 0 to 10, where 10 is most relevant\",\n",
        "        ge=0,\n",
        "        le=10,\n",
        "    )\n",
        "\n",
        "class RerankedResults(BaseModel):\n",
        "    labels: list[Label] = Field(description=\"List of labeled and ranked chunks\")\n",
        "\n",
        "    @field_validator(\"labels\")\n",
        "    @classmethod\n",
        "    def model_validate(cls, v: list[Label]) -> list[Label]:\n",
        "        return sorted(v, key=lambda x: x.relevancy, reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adjust_time_filter_to_week(time_filter):\n",
        "    \"\"\"\n",
        "    특정 날짜(YYYY-MM-DD)가 주어진 경우, 해당 날짜를 포함하는 주(월~일)의\n",
        "    첫 번째 날(월요일)과 마지막 날(일요일)로 변환하는 함수.\n",
        "\n",
        "    :param time_filter: dict, {\"start_date\": datetime, \"end_date\": datetime}\n",
        "    :return: dict, {\"start_date\": datetime, \"end_date\": datetime}\n",
        "    \"\"\"\n",
        "    # Extract start_date and end_date from time_filter\n",
        "    start_date = time_filter.start_date\n",
        "    end_date = time_filter.end_date\n",
        "\n",
        "    # Handle the case where start_date or end_date is None\n",
        "    if start_date is None or end_date is None:\n",
        "        if start_date is not None and end_date is None:\n",
        "            start_of_week = start_date - timedelta(days=start_date.weekday())  # 월요일 찾기\n",
        "            end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "            return {\n",
        "                \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "                \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "            }\n",
        "        elif end_date is not None and start_date is None:\n",
        "            start_of_week = end_date - timedelta(days=end_date.weekday())  # 월요일 찾기\n",
        "            end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "            return {\n",
        "                \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "                \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "            }\n",
        "        else:\n",
        "            return None  # or return the time_filter as is if you prefer\n",
        "\n",
        "    # 날짜가 동일한 경우, 주의 첫 번째 날(월요일)과 마지막 날(일요일)로 변경\n",
        "    if start_date.year == end_date.year and start_date.month==end_date.month and start_date.day==end_date.day:\n",
        "        start_of_week = start_date - timedelta(days=start_date.weekday())  # 월요일 찾기\n",
        "        end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "        return {\n",
        "            \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "            \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "        }\n",
        "\n",
        "    # 날짜가 다르면 기존 time_filter 유지\n",
        "    return {\n",
        "        \"start_date\": start_date,\n",
        "        \"end_date\": end_date\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_search_query_response(response: str, question: str) -> SearchQuery:\n",
        "    \"\"\"\n",
        "    ChatClovaX 응답을 SearchQuery 객체로 파싱\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 응답이 JSON 문자열이라고 가정\n",
        "        data = json.loads(response.content)\n",
        "        # time_filter가 null이면 빈 dict으로 변환\n",
        "        if data.get(\"time_filter\") is None:\n",
        "            data[\"time_filter\"] = {}\n",
        "        # query 필드가 없으면 원본 question을 사용\n",
        "        if \"query\" not in data:\n",
        "            data[\"query\"] = question\n",
        "        return SearchQuery(**data)\n",
        "    except Exception:\n",
        "        # 파싱 실패 시, 기본값 반환\n",
        "        return SearchQuery(query=question, time_filter=TimeFilter())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_query_date(question):\n",
        "    today = datetime(2025, 1, 25)\n",
        "    days_since_last_friday = (today.weekday() - 4) % 7\n",
        "    last_friday = today - timedelta(days=days_since_last_friday)\n",
        "    issue_date = last_friday.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # ChatClovaX 인스턴스 생성\n",
        "    chat = ChatClovaX(\n",
        "        model=\"HCX-005\",\n",
        "        temperature = 0\n",
        "    )\n",
        "\n",
        "    # 프롬프트: 반드시 SearchQuery 포맷(JSON)으로만 답변하게 유도\n",
        "    system_prompt = f\"\"\"\n",
        "    You are an AI assistant that extracts date ranges from financial queries.\n",
        "    The current report date is {issue_date}.\n",
        "    Your task is to extract the relevant date or date range from the user's query\n",
        "    and format it in YYYY-MM-DD format.\n",
        "    If no date is specified, answer with None value.\n",
        "    Return your answer as a JSON object in this format:\n",
        "    {{\n",
        "        \"query\": \"<원본 질문>\",\n",
        "        \"time_filter\": {{\"start_date\": \"YYYY-MM-DD\", \"end_date\": \"YYYY-MM-DD\"}} or {{\"start_date\": null, \"end_date\": null}}\n",
        "    }}\n",
        "    답변은 반드시 위 JSON 형태로만 해.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "    \n",
        "    response = chat.invoke(messages)\n",
        "    # ChatClovaX 응답을 SearchQuery로 파싱\n",
        "    search_query = parse_search_query_response(response, question)\n",
        "\n",
        "    # adjust_time_filter_to_week는 기존 함수 그대로 사용\n",
        "    parsed_dates = adjust_time_filter_to_week(search_query.time_filter)\n",
        "\n",
        "    if parsed_dates:\n",
        "        start = parsed_dates['start_date']\n",
        "        end = parsed_dates['end_date']\n",
        "    else:\n",
        "        start = None\n",
        "        end = None\n",
        "\n",
        "    if start is None or end is None:\n",
        "        expr = None\n",
        "    else:\n",
        "        expr = f\"issue_date >= '{start.strftime('%Y%m%d')}' AND issue_date <= '{end.strftime('%Y%m%d')}'\"\n",
        "    return expr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_query_date(question):\n",
        "    today = datetime(2025, 1, 25)\n",
        "    days_since_last_friday = (today.weekday() - 4) % 7\n",
        "    last_friday = today - timedelta(days=days_since_last_friday)\n",
        "    issue_date = last_friday.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # ChatClovaX 인스턴스 생성\n",
        "    chat = ChatClovaX(\n",
        "        model=\"HCX-005\",\n",
        "        temperature = 0\n",
        "    )\n",
        "\n",
        "    # 프롬프트: 반드시 SearchQuery 포맷(JSON)으로만 답변하게 유도\n",
        "    system_prompt = f\"\"\"\n",
        "    You are an AI assistant that extracts date ranges from financial queries.\n",
        "    The current report date is {issue_date}.\n",
        "    Your task is to extract the relevant date or date range from the user's query\n",
        "    and format it in YYYY-MM-DD format.\n",
        "    If no date is specified, answer with None value.\n",
        "    Return your answer as a JSON object in this format:\n",
        "    {{\n",
        "        \"query\": \"<원본 질문>\",\n",
        "        \"time_filter\": {{\"start_date\": \"YYYY-MM-DD\", \"end_date\": \"YYYY-MM-DD\"}} or {{\"start_date\": null, \"end_date\": null}}\n",
        "    }}\n",
        "    답변은 반드시 위 JSON 형태로만 해.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "    \n",
        "    response = chat.invoke(messages)\n",
        "    # ChatClovaX 응답을 SearchQuery로 파싱\n",
        "    search_query = parse_search_query_response(response, question)\n",
        "\n",
        "    # adjust_time_filter_to_week는 기존 함수 그대로 사용\n",
        "    parsed_dates = adjust_time_filter_to_week(search_query.time_filter)\n",
        "\n",
        "    if parsed_dates:\n",
        "        start = parsed_dates['start_date']\n",
        "        end = parsed_dates['end_date']\n",
        "    else:\n",
        "        start = None\n",
        "        end = None\n",
        "\n",
        "    if start is None or end is None:\n",
        "        expr = None\n",
        "    else:\n",
        "        expr = f\"issue_date >= '{start.strftime('%Y%m%d')}' AND issue_date <= '{end.strftime('%Y%m%d')}'\"\n",
        "    return expr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_list(example):\n",
        "    if isinstance(example[\"contexts\"], list):\n",
        "        contexts = example[\"contexts\"]\n",
        "    else:\n",
        "        try:\n",
        "            contexts = json.loads(example[\"contexts\"])\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON Decode Error: {example['contexts']} - {e}\")\n",
        "            contexts = []\n",
        "    return {\"contexts\": contexts}\n",
        "\n",
        "text_prompt = PromptTemplate.from_template(\n",
        "'''\n",
        "today is '2025-01-25'. You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "If question has date expressions, context already filtered with the date expression, so ignore about the date and answer without it.\n",
        "Answer in Korean. Answer in detail.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:'''\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 평가 결과 모델\n",
        "class GroundnessQuestionScore(BaseModel):\n",
        "    score: str = Field(\n",
        "        description=\"질문과 답변이 명확히 관련 있으면 'yes', 아니면 'no'\"\n",
        "    )\n",
        "\n",
        "class GroundnessAnswerRetrievalScore(BaseModel):\n",
        "    score: str = Field(\n",
        "        description=\"검색된 문서와 답변이 명확히 관련 있으면 'yes', 아니면 'no'\"\n",
        "    )\n",
        "\n",
        "class GroundnessQuestionRetrievalScore(BaseModel):\n",
        "    score: str = Field(\n",
        "        description=\"검색된 문서와 질문이 명확히 관련 있으면 'yes', 아니면 'no'\"\n",
        "    )\n",
        "\n",
        "class GroundednessCheckerClovaX:\n",
        "    \"\"\"\n",
        "    HyperCLOVA X 기반의 정확성 평가기 (OpenAI 버전과 동일한 구조)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm, target=\"retrieval-answer\"):\n",
        "        self.llm = llm\n",
        "        self.target = target\n",
        "\n",
        "\n",
        "    def create(self):\n",
        "        # 프롬프트 선택\n",
        "        if self.target == \"retrieval-answer\":\n",
        "            template = \"\"\"\n",
        "                You are a grader assessing relevance of a retrieved document to a user question.\n",
        "                Here is the retrieved document: {context}\n",
        "                Here is the answer: {answer}\n",
        "                If the document contains keyword(s) or semantic meaning related to the user answer, grade it as relevant.\n",
        "                Return your answer as a JSON object: {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\n",
        "                답변은 반드시 위 JSON 형태로만 해.\n",
        "            \"\"\"\n",
        "            input_vars = [\"context\", \"answer\"]\n",
        "        elif self.target == \"question-answer\":\n",
        "            template = \"\"\"\n",
        "                You are a grader assessing whether an answer appropriately addresses the given question.\n",
        "                Here is the question: {question}\n",
        "                Here is the answer: {answer}\n",
        "                If the answer directly addresses the question and provides relevant information, grade it as relevant.\n",
        "                Consider both semantic meaning and factual accuracy in your assessment.\n",
        "                Return your answer as a JSON object: {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\n",
        "                답변은 반드시 위 JSON 형태로만 해.\n",
        "            \"\"\"\n",
        "            input_vars = [\"question\", \"answer\"]\n",
        "        elif self.target == \"question-retrieval\":\n",
        "            template = \"\"\"\n",
        "                You are a grader assessing whether a retrieved document is relevant to the given question.\n",
        "                Here is the question: {question}\n",
        "                Here is the retrieved document: {context}\n",
        "                If the document contains information that could help answer the question, grade it as relevant.\n",
        "                Consider both semantic meaning and potential usefulness for answering the question.\n",
        "                Return your answer as a JSON object: {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\n",
        "                답변은 반드시 위 JSON 형태로만 해.\n",
        "            \"\"\"\n",
        "            input_vars = [\"question\", \"context\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid target: {self.target}\")\n",
        "\n",
        "        def chain_func(**kwargs):\n",
        "            prompt = template.format(**{k: kwargs[k] for k in input_vars})\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": prompt}\n",
        "            ]\n",
        "            response = self.llm.invoke(messages)\n",
        "            # 응답에서 yes/no만 추출\n",
        "            answer = response.content.strip().replace('\"', '').replace(\"'\", \"\").lower()\n",
        "            if answer not in [\"yes\", \"no\"]:\n",
        "                import re\n",
        "                match = re.search(r'\\b(yes|no)\\b', answer)\n",
        "                if match:\n",
        "                    answer = match.group(1)\n",
        "                else:\n",
        "                    raise ValueError(f\"Invalid response: {response}\")\n",
        "\n",
        "            # Pydantic 모델 매핑\n",
        "            if self.target == \"retrieval-answer\":\n",
        "                return GroundnessAnswerRetrievalScore(score=answer)\n",
        "            elif self.target == \"question-answer\":\n",
        "                return GroundnessQuestionScore(score=answer)\n",
        "            elif self.target == \"question-retrieval\":\n",
        "                return GroundnessQuestionRetrievalScore(score=answer)\n",
        "\n",
        "        return chain_func\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_answer_relevant = GroundednessCheckerClovaX(\n",
        "  llm=ChatClovaX(model=\"HCX-005\"), target='question-answer'\n",
        ").create()\n",
        "\n",
        "@chain\n",
        "def kill_table(result):\n",
        "    if question_answer_relevant(question=result['question'], answer=result['text']}).score == 'no':\n",
        "        result['context'] = table_chain.invoke({'question': result['question']})\n",
        "    else:\n",
        "        result['context'] = result['text']\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "URI = 'http://127.0.0.1:19530'\n",
        "\n",
        "text_db = Milvus(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args = {'uri': URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='text_db'\n",
        ")\n",
        "\n",
        "image_db = Milvus(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args = {'uri': URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='image_db'\n",
        ")\n",
        "\n",
        "raptor_db = Milvus(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args = {'uri': URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='raptor_db'\n",
        ")\n",
        "\n",
        "table_db = Milvus(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args = {'uri': URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='table_db'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filepath = './chunked_jsonl/text_semantic_per_80.jsonl'\n",
        "\n",
        "splitted_doc_text = []\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        if line.startswith('\\n('):\n",
        "            continue\n",
        "        data = json.loads(line)\n",
        "\n",
        "        doc = Document(\n",
        "            page_content=data['page_content'],\n",
        "            metadata=data['metadata']\n",
        "        )\n",
        "        splitted_doc_text.append(doc)\n",
        "\n",
        "filepath = './chunked_jsonl/table_v7.jsonl'\n",
        "\n",
        "splitted_doc_table = []\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        if line.startswith('\\n('):\n",
        "            continue\n",
        "        data = json.loads(line)\n",
        "\n",
        "        doc = Document(\n",
        "            page_content=data['page_content'],\n",
        "            metadata=data['metadata']\n",
        "        )\n",
        "        splitted_doc_table.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm25_retriever_table = KiwiBM25Retriever.from_documents(\n",
        "    splitted_doc_table\n",
        ")\n",
        "\n",
        "bm25_retriever_table.k = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm25_retriever_text = KiwiBM25Retriever.from_documents(\n",
        "    splitted_doc_text\n",
        ")\n",
        "bm25_retriever_text.k = 50\n",
        "\n",
        "bm25_2_retriever_text = KiwiBM25Retriever.from_documents(\n",
        "    splitted_doc_text\n",
        ")\n",
        "bm25_2_retriever_text.k = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    # 각 문서의 issue_date와 page_content를 함께 출력하도록 포맷합니다.\n",
        "    return \"\\n\\n\".join(\n",
        "        f\"Issue Date: {doc.metadata.get('issue_date', 'Unknown')}\\nContent: {doc.page_content}\"\n",
        "        for doc in docs\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_prompt = PromptTemplate.from_template(\n",
        "'''You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved table to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Answer in Korean. Answer in detail.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:'''\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatClovaX(model='HCX-005', temperature=0)\n",
        "\n",
        "answer = []\n",
        "\n",
        "text_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(context_raw=lambda x: RunnableLambda(\n",
        "            lambda _: text_db.as_retriever(\n",
        "                search_kwargs={'expr': x['expr'], 'k': 25}\n",
        "            ).invoke(x['question'])\n",
        "        ).invoke({}),\n",
        "    ).assign(\n",
        "        formatted_context=lambda x: format_docs(x['context_raw'])\n",
        "    )\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['formatted_context'],  \n",
        "        }\n",
        "    )\n",
        "    | text_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(milvus=lambda x: RunnableLambda(\n",
        "            lambda _: table_db.as_retriever(\n",
        "                search_kwargs={'expr': x['expr'], 'k': 10}\n",
        "            ).invoke(x['question'])\n",
        "        ).invoke({}),\n",
        "        bm25_raw=lambda x: bm25_retriever_table.invoke(x['question'])\n",
        "    ).assign(\n",
        "        bm25_filtered=lambda x: [\n",
        "            doc for doc in x[\"bm25_raw\"]\n",
        "            if not x[\"expr\"] or (\n",
        "                x[\"expr\"].split(\"'\")[1] <= doc.metadata.get(\"issue_date\", \"\") <= x[\"expr\"].split(\"'\")[3]\n",
        "            )\n",
        "        ],\n",
        "    ).assign(\n",
        "        context=lambda x: x['milvus'] + x['bm25_filtered']\n",
        "    )\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['context'],\n",
        "        }\n",
        "    )\n",
        "    | table_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "general_prompt = PromptTemplate.from_template(\n",
        "  '''You are question-answering AI chatbot about financial reports.\n",
        "  주어진 두 개의 정보는 table과 text에서 가져온 정보들이야. 이 정보를 바탕으로 질문에 대해 자세히 설명해줘.\n",
        "  \n",
        "  If one of the table or text says it doesn't know or it can't answer, don't mention with that.\n",
        "  And some questions may not be answered simply with context, but rather require inference. In those cases, answer by inference. \n",
        "  \n",
        "  #Question:\n",
        "  {question}\n",
        "\n",
        "  #Text Answer:\n",
        "  {text}\n",
        "\n",
        "  #Table Answer:\n",
        "  {table}\n",
        "  '''\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "general_chain = (\n",
        "    RunnableParallel(\n",
        "        question=RunnablePassthrough(),\n",
        "        text=text_chain,\n",
        "        table=table_chain,\n",
        "    )\n",
        "    | general_prompt \n",
        "    | llm\n",
        ")\n",
        "\n",
        "\n",
        "predict_chain = (\n",
        "    RunnableParallel(\n",
        "        question=RunnablePassthrough(),\n",
        "        text=text_chain,\n",
        "        table=table_chain,\n",
        "    )\n",
        "    | general_prompt \n",
        "    | llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata_field_info = [\n",
        "  AttributeInfo(\n",
        "    name='source',\n",
        "    description='문서의 번호. 네 자리의 숫자와 \"호\"로 이루어져 있다. 현재 1090호부터 1120호까지 존재한다.',\n",
        "    type='string',\n",
        "  ),\n",
        "]\n",
        "\n",
        "prompt_query = get_query_constructor_prompt(\n",
        "  'summary of weekly financial report about bonds',\n",
        "  metadata_field_info\n",
        ")\n",
        "\n",
        "output_parser = StructuredQueryOutputParser.from_components()\n",
        "query_constructor = prompt_query | llm | output_parser\n",
        "\n",
        "\n",
        "prompt_raptor = PromptTemplate.from_template(\n",
        "'''You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Answer in Korean. Answer in detail.\n",
        "If the context mentions an unrelated date, do not mention that part.\n",
        "Summarize and organize your answers based on the various issues that apply to the period.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:'''\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever_raptor = SelfQueryRetriever(\n",
        "  query_constructor=query_constructor,\n",
        "  vectorstore=raptor_db,\n",
        "  structured_query_translator=MilvusTranslator(),\n",
        "  search_kwargs={'k': 10}\n",
        ")\n",
        "\n",
        "raptor_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(context=lambda x: retriever_raptor.invoke(x['question']))\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['context'],\n",
        "        }\n",
        "    )\n",
        "    | prompt_raptor\n",
        "    | llm\n",
        ")\n",
        "\n",
        "\n",
        "raptor_date_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(context=lambda x: RunnableLambda(\n",
        "            lambda _: raptor_db.as_retriever(\n",
        "                search_kwargs={'expr': x['expr'], 'k': 10}\n",
        "            ).invoke(x['question'])\n",
        "        ).invoke({})\n",
        "    )\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['context'],\n",
        "        }\n",
        "    )\n",
        "    | prompt_raptor\n",
        "    | llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_routing = PromptTemplate.from_template(\n",
        "  '''주어진 사용자 질문을 `요약`, `예측`, 또는 `일반` 중 하나로 분류하세요. 한 단어 이상으로 응답하지 마세요.\n",
        "  \n",
        "  <question>\n",
        "  {question}\n",
        "  </question>\n",
        "  \n",
        "  Classification:'''\n",
        ")\n",
        "\n",
        "chain_routing = (\n",
        "  {'question': RunnablePassthrough()}\n",
        "  | prompt_routing\n",
        "  | llm\n",
        "  | StrOutputParser()\n",
        ")\n",
        "\n",
        "prompt_routing_2 = PromptTemplate.from_template(\n",
        "  '''주어진 사용자 질문을 `날짜`, `호수` 중 하나로 분류하세요. 한 단어 이상으로 응답하지 마세요.\n",
        "  \n",
        "  <question>\n",
        "  {question}\n",
        "  </question>\n",
        "  \n",
        "  Classification:'''\n",
        ")\n",
        "\n",
        "chain_routing_2 = (\n",
        "  {'question': RunnablePassthrough()}\n",
        "  | prompt_routing_2\n",
        "  | llm\n",
        "  | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'start_date'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-69-7975522c70c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraptor_date_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'question'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'2025년 1월 보고서 요약해줘'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'expr'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_query_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2025년 1월 보고서 요약해줘'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-46-660a4d7b6f35>\u001b[0m in \u001b[0;36mget_query_date\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mtime_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mparsed_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madjust_time_filter_to_week\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_filter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparsed_dates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-43-fe9b20d9556b>\u001b[0m in \u001b[0;36madjust_time_filter_to_week\u001b[1;34m(time_filter)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Extract start_date and end_date from time_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mstart_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_filter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mend_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_filter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'start_date'"
          ]
        }
      ],
      "source": [
        "raptor_date_chain({'question': '2025년 1월 보고서 요약해줘', 'expr': get_query_date('2025년 1월 보고서 요약해줘')})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def route_2(info):\n",
        "  if '날짜' in info['topic'].lower():\n",
        "    return raptor_date_chain\n",
        "  else:\n",
        "    return raptor_chain\n",
        "  \n",
        "def route(info):\n",
        "  if '요약' in info['topic'].lower():\n",
        "    return route_2(info)\n",
        "  elif '예측' in info['topic'].lower():\n",
        "    return predict_chain\n",
        "  else:\n",
        "    return general_chain\n",
        "\n",
        "\n",
        "full_chain = (\n",
        "  {'topic': chain_routing, 'question': itemgetter('question')}\n",
        "  | RunnableLambda(\n",
        "    route\n",
        "  )\n",
        "  | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever_image = image_db.as_retriever(search_kwargs={'k': 3})\n",
        "\n",
        "retrieval_answer_relevant = GroundednessCheckerClovaX(\n",
        "  llm, target='retrieval-answer'\n",
        ").create()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from PIL import Image\n",
        "\n",
        "def ask(question):\n",
        "    expr = get_query_date(question)\n",
        "    answer = full_chain.invoke({'question': question})\n",
        "    print(answer)\n",
        "    rc('font', family='Malgun Gothic')\n",
        "    plt.rcParams['axes.unicode_minus'] = False        \n",
        "    context = retriever_image.invoke(question, expr=expr)\n",
        "    for i in context:\n",
        "        rar = retrieval_answer_relevant(context=i, answer=answer)\n",
        "        if rar.score=='yes':\n",
        "            plt.title('참고 자료')\n",
        "            image_path = i.metadata['image'].replace('raw_pdf_copy3', 'parsed_pdf')\n",
        "            img = Image.open(image_path)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
